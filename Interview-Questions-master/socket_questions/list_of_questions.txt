►
http://www.globalguideline.com/forum/viewtopic.php?id=365
http://interviewquestionsanswers.org/forum/topic-1025-socket-programming-interview-questions-and-answers-page-1.html
http://interviewstar.blogspot.in/2010/08/socket-programming-interview-questions.html
================================================================================
►What is urget pointer in TCP/IP header? 
Sol:
The Urgent Pointer is used when some information has to reach the server ASAP. 
When the TCP/IP stack at the other end sees a packet using the Urgent Pointer, 
it is duty bound to stop all it's doing and immediately send this packet to 
the relevant server. Since the packet is plucked out of the processing 
queue and acted upon immediately, it is known as an Out Of Band (OOB) packet 
and the data is called Out Of Band (OOB) data. The Urgent Pointer is usually 
used in Telnet, where an immediate response (e.g. the echoing of characters) 
is desirable. 
================================================================================
► What are the different states of TCP/IP connection?
Sol: There are total 11 different states of TCP/IP connection:
1.  SYN_SEND Indicates active open.
2.  SYN_RECEIVED Server just received SYN from the client.
3.  ESTABLISHED Client received server's SYN and session is established.
4.  LISTEN Server is ready to accept connection.
5.  FIN_WAIT_1 Indicates active close.
6.  TIMED_WAIT Client enters this state after active close.
7.  CLOSE_WAIT Indicates passive close. Server just received first FIN from a client.
8.  FIN_WAIT_2 Client just received acknowledgment of its first FIN from the server.
9.  LAST_ACK Server is in this state when it sends its own FIN.
10. CLOSED Server received ACK from client and connection is closed. 

================================================================================
► Users are complaining of delays when using the network What would you do?
Sol:
   That's a fairly vague (and typical) complaint.

I'd first try to get the user to identify what network resource is 
slow (email, external web browsing, intranet, network file access, etc.) 
I'd probably also have the user swap locations with another coworker 
to identify if the problem lies in the hardware (computer, network 
cable, switch port, etc.) that is specific to that location.

If neither user identifies a difference, then I'd chalk it up to 
poorly managed expectations and work to explain to the user that j
ust because this is a business network, it doesn't necessarily mean 
that it'll be faster than their single machine on cable/dsl at home.

However, if both users see a difference, then I'd investigate the 
items that are specific to the slow machine's network. For example, 
I'd check that the switch port is set to full duplex, that the 
computer's network drivers are up to date, etc. 

Please chosse any node where you are facing dealys, And run a 
packet capture like Wireshark,
You may also use a Network anylazer[ many free softwares available] 
by configuring Netflow on switch if it support & check what kind 
of packets are flowing in your network and you could surely find 
the reason creating delays.

Also check cables & Switch interfaces for errors & CRC, some faulty 
cables create errors which lead to pkt drops & slow responce


================================================================================
► What is difference between select and poll  system call?
Sol:
The select() API requires that the application pass in an array 
of bits in which one bit is used to represent each descriptor number. 
When descriptor numbers are very large, it can overflow the 
30KB allocated memory size, forcing multiple iterations of the 
process. This overhead can adversely affect performance.

The poll() API allows the application to pass an array of 
structures rather than an array of bits. Because each pollfd 
structure can contain up to 8 bytes, the application only needs 
to pass one structure for each descriptor, even if descriptor 
numbers are very large.

From Stackoverflow:
===================
The select() call has you create three bitmasks to mark which 
sockets and file descriptors you want to watch for reading, 
writing, and errors, and then the operating system marks which 
ones in fact have had some kind of activity; poll() has 
you create a list of descriptor IDs, and the operating system 
marks each of them with the kind of event that occurred.

The select() method is rather clunky and inefficient.
    1. There are typically more than a thousand potential file 
descriptors available to a process. If a long-running process 
has only a few descriptors open, but at least one of them 
has been assigned a high number, then the bitmask passed to 
select() has to be large enough to accomodate that highest 
descriptor — so whole ranges of hundreds of bits will be 
unset that the operating system has to loop across on 
every select() call just to discover that they are unset.

    2. Once select() returns, the caller has to loop over 
all three bitmasks to determine what events took place. 
In very many typical applications only one or two file 
descriptors will get new traffic at any given moment, yet 
all three bitmasks must be read all the way to the end 
to discover which descriptors those are.

    3. Because the operating system signals you about activity 
by rewriting the bitmasks, they are ruined and are no longer 
marked with the list of file descriptors you want to listen to. 
You either have to rebuild the whole bitmask from some other 
list that you keep in memory, or you have to keep a duplicate 
copy of each bitmask and memcpy() the block of data over on 
top of the ruined bitmasks after each select() call.

So the poll() approach works much better because you can 
keep re-using the same data structure.

In fact, poll() has inspired yet another mechanism in modern 
Linux kernels: epoll() which improves even more upon the mechanism 
to allow yet another leap in scalability, as today's servers 
often want to handle tens of thousands of connections at once. 
This is a good introduction to the effort:    

================================================================================
►What is difference between blocking and non blocking sockets?
Sol:
    Blocking vs. non-blocking sockets

So far in this chapter, you've seen that select() can be used to detect 
when data is available to read from a socket. However, there are times 
when its useful to be able to call send(), recv(), connect(), accept(), 
etc without having to wait for the result.

For example, let's say that you're writing a web browser. You try to 
connect to a web server, but the server isn't responding. When a user 
presses (or clicks) a stop button, you want the connect() API to stop 
trying to connect.

With what you've learned so far, that can't be done. When you issue 
a call to connect(), your program doesn't regain control until either 
the connection is made, or an error occurs.

The solution to this problem is called "non-blocking sockets".
By default, TCP sockets are in "blocking" mode. For example, when 
you call recv() to read from a stream, control isn't returned to your 
program until at least one byte of data is read from the remote site. 
This process of waiting for data to appear is referred to as "blocking". 
The same is true for the write() API, the connect() API, etc. When you 
run them, the connection "blocks" until the operation is complete.

Its possible to set a descriptor so that it is placed in "non-blocking" 
mode. When placed in non-blocking mode, you never wait for an operation 
to complete. This is an invaluable tool if you need to switch between 
many different connected sockets, and want to ensure that none of them 
cause the program to "lock up."

If you call "recv()" in non-blocking mode, it will return any data 
that the system has in it's read buffer for that socket. But, it won't 
wait for that data. If the read buffer is empty, the system will return 
from recv() immediately saying ``"Operation Would Block!"''.

The same is true of the send() API. When you call send(), it puts the 
data into a buffer, and as it's read by the remote site, it's removed 
from the buffer. If the buffer ever gets "full", the system will 
return the error 'Operation Would Block" the next time you try to 
write to it.

Non-blocking sockets have a similar effect on the accept() API. 
When you call accept(), and there isn't already a client connecting to 
you, it will return 'Operation Would Block', to tell you that it 
can't complete the accept() without waiting...

The connect() API is a little different. If you try to call connect() 
in non-blocking mode, and the API can't connect instantly, it will 
return the error code for 'Operation In Progress'. When you call 
connect() again, later, it may tell you 'Operation Already In Progress' 
to let you know that it's still trying to connect, or it may give 
you a successful return code, telling you that the connect has been made.

Going back to the "web browser" example, if you put the socket that 
was connecting to the web server into non-blocking mode, you could 
then call connect(), print a message saying "connecting to host 
www.floofy.com..." then maybe do something else, and them come back to 
connect() again. If connect() works the second time, you might print 
"Host contacted, waiting for reply..." and then start calling 
send() and recv(). If the connect() is still pending, you might check 
to see if the user has pressed a "abort" button, and if so, call 
close() to stop trying to connect.

Non-blocking sockets can also be used in conjunction with the 
select() API. In fact, if you reach a point where you actually WANT 
to wait for data on a socket that was previously marked as "non-blocking", 
you could simulate a blocking recv() just by calling select() first, 
followed by recv().

The "non-blocking" mode is set by changing one of the socket's "flags". 
The flags are a series of bits, each one representing a different 
capability of the socket. So, to turn on non-blocking mode requires 
three steps:

1. Call the fcntl() API to retrieve the socket descriptor's current 
   flag settings into a local variable.
2. In our local variable, set the O_NONBLOCK (non-blocking) flag on. 
   (being careful, of course, not to tamper with the other flags)
3. Call the fcntl() API to set the flags for the descriptor to the 
   value in our local variable.

 
================================================================================

► What is difference between polling/Non blocking based socket and 
Interrupt based socket?
Sol:
    Non blocking sockets
    ====================
It's convenient to use sockets that don,t block in case where an 
I/O request might not get complete imidiatley, causing the process 
to be suspended waiting completion of the request. Once the socket 
has been created via the socket call, It may be marked non-blocking 
by ioctl() as follows. 

#include<ioctl.h>
...
int s, on;
...
on = 1
s = socket(AF_INET,SOCK_STREAM,0);
...
if(ioctl(s,FIONBIO,&on) < 0) {
    perror("ioctl F_SETFL,FNDELAY");
    exit(1);
}
...

When performing non-blocking I/O on socket, we must be careful 
to check for the error EWOULDBLOCK (sstored in global errno), which 
occurs when an operation would normally block, but the socket 
it was performed on is marked as non-blocking.
In particular accept(),connect, send, recv, read, and write 
can all return EWOULDBLOCK.


    Interrupt-driven socket I/O
    ===========================
The SIGIO signal allows a process to be notified via a signal 
when a socket (or more generally, a file descriptor) has data waiting 
to be read. Use of the SIGIO facility requires three steps:
    1. The process must set up a SIGIO signal handler by use of the 
       signal() or sigaction() calls.
    2. The process must set the process ID or process group ID that 
       is to receive notification of pending input to its own process ID 
       or to the process group ID of its process group (note that the 
       default process group of a socket is group zero).
       This is accomplished by use of an ioctl() call.
    3. The process must enable asynchronous notification of pending 
       I/O requests with another ioctl() call.

    Use of asynchronous notification of I/O requests:-
The following sample code shows how to allow a process to receive 
information on pending I/O requests as they occur for a socket. 
With the addition of a handler for SIGURG, this code can also be 
used to prepare for receipt of SIGURG signals.

#include <ioctl.h>
#include <sys/types.h>
...
int io_handler(), on;
pid_t pgrp;
...
on=1;
signal(SIGIO, io_handler);
/* Set the process receiving SIGIO/SIGURG signals to us */
pgrp=getpid();
if (ioctl(s, SIOCSPGRP, &pgrp) < 0) {
perror("ioctl F_SETOWN");
exit(1);
}
/* Allow receipt of asynchronous I/O signals */

if (ioctl(s, FIOASYNC, &on) < 0) {
perror("ioctl F_SETFL, FASYNC");
exit(1);
}

 

================================================================================
► Explain the tcp windowing concept.
Sol:
    TCP windowing concept is primarily used to avoid congestion 
in the traffic. It controls the amount of unacknowledged data a 
sender can send before it gets an acknowledgement back from the 
receiver that it has received it.

================================================================================
► Explain TIME_WAIT state in TCP connection.
Sol:
    The device receiving the initial FIN may have to wait a fairly long 
time (in networking terms) in the CLOSE-WAIT state for the application 
it is serving to indicate that it is ready to shut down. TCP cannot make 
any assumptions about how long this will take. During this period of 
time, the server in our example above may continue sending data, and 
the client will receive it. However, the client will not send data to 
the server.

Eventually, the second device (the server in our example) will send a 
FIN to close its end of the connection. The device that originally 
initiated the close (the client above) will send an ACK for this FIN. 
However, the client cannot immediately go to the CLOSED state right 
after sending that ACK. The reason is that it must allow time for the 
ACK to travel to the server. Normally this will be quick, but delays 
might result in it being slowed down somewhat.

The TIME-WAIT state is required for two main reasons. The first is to 
provide enough time to ensure that the ACK is received by the other 
device, and to retransmit it if it is lost. The second is to provide 
a “buffering period” between the end of this connection and any 
subsequent ones. If not for this period, it is possible that packets 
from different connections could be mixed, creating confusion.

The standard specifies that the client should wait double a particular 
length of time called the maximum segment lifetime (MSL) before 
finishing the close of the connection. The TCP standard defines 
MSL as being a value of 120 seconds (2 minutes). In modern networks 
this is an eternity, so TCP allows implementations to choose a lower 
value if it is believed that will lead to better operation.


================================================================================
► What Is Socket?
Sol:
    A network socket is an endpoint of an inter-process communication 
flow across a computer network. Today, most communication between computers 
is based on the Internet Protocol; therefore most network sockets are Internet 
sockets.

A socket API is an application programming interface (API), usually provided 
by the operating system, that allows application programs to control and use 
network sockets. Internet socket APIs are usually based on the Berkeley sockets 
standard.

A socket address is the combination of an IP address and a port number, much 
like one end of a telephone connection is the combination of a phone number 
and a particular extension. Based on this address, internet sockets deliver 
incoming data packets to the appropriate application process or thread.

It is important to note that these sockets are software, not hardware, like a 
wall socket. So, yes, you have a much greater chance of being shocked by a 
wall socket than by a networking socket.
================================================================================
► How does the race condition occur?
Sol:
    It occurs when two or more processes are reading or writing some shared 
data and the final result depends on who runs precisely when.
================================================================================
► What is multiprogramming?
Sol:
    Multiprogramming is a rudimentary form of parallel processing in which 
several programs are run at the same time on a uniprocessor. Since there is 
only one processor , there can be no true simultaneous execution of different 
programs. Instead, the operating system executes part of one program, then 
part of another, and so on. To the user it appears that all programs are 
executing at the same time.

If the machine has the capability of causing an interrupt after a specified 
time interval, then the operating system will execute each program for a 
given length of time, regain control, and then execute another program 
for a given length of time, and so on. In the absence of this mechanism, 
the operating system has no choice but to begin to execute a program with 
the expectation, but not the certainty, that the program will eventually 
return control to the operating system.

If the machine has the capability of protecting memory , then a bug in one 
program is less likely to interfere with the execution of other programs. 
In a system without memory protection, one program can change the contents 
of storage assigned to other programs or even the storage assigned to the 
operating system. The resulting system crashes are not only disruptive, 
they may be very difficult to debug since it may not be obvious which 
of several programs is at fault.
================================================================================
► Name the seven layers of the OSI Model and describe them briefly?
Sol:
    Physical Layer - covers the physical interface between devices and the 
rules by which bits are passed from one to another.

Data Link Layer - attempts o make the physical link reliable and provides the 
means to activate, maintain, and deactivate the link.

Network Layer - provides for the transfer of information between end systems 
across some sort communications network.

Transport Layer - provides a mechanism for the exchange of data between end 
system.

Session Layer - provides the mechanism for controlling the dialogue between 
applications in end systems.

Presentation Layer - defines the format of the data to be exchanged between 
applications and offers application programs a set of data transformation 
services.

Application Layer - provides a means for application programs to access the 
OSI environment. 
================================================================================
► What is the difference between TCP and UDP?
Sol:
    TCP and UDP are both transport-level protocols. TCP is designed to 
provide reliable communication across a variety of reliable and unreliable 
networks and internets.

UDP provides a connectionless service for application-level procedures. 
Thus, UDP is basically an unreliable service; delivery and duplicate protection 
are not guareented. 
================================================================================
► What does a socket consists of?
Sol:
    The combination of an IP address and a port number is called a socket. 
================================================================================
► What is the difference between a NULL pointer and a void pointer?
Sol:
    A NULL pointer is a pointer of any type whose value is zero. A void 
pointer is a pointer to an object of an unknown type, and is guaranteed to 
have enough bits to hold a pointer to any object. A void pointer is not 
guaranteed to have enough bits to point to a function (though in general 
practice it does). 
================================================================================
►  Socket Programming Interview Questions
Sol:
    01. User(s) are complaining of delays when using the network. What 
        would you do?
    02. What are some of the problems associated with operating a switched LAN?
    03. Name some of the ways of combining TCP/IP traffic and SNA traffic 
        over the same link.
    04. What sort of cabling is suitable for Fast Ethernet protocols?
    05. What is a Class D IP address?
    06. Why do I sometimes lose a server's address when using more than 
        one server?
    07. What is Firewall?
    08. How do I monitor the activity of sockets?
    09. How would I put my socket in non-blocking mode?
    10. What are RAW sockets?
    11. What is the role of TCP protocol and IP protocol.
    12. What is UDP?
    13. How can I make my server a daemon?
    14. How should I choose a port number for my server?
    15. Layers in TCP/IP
    16. How can I be sure that a UDP message is received?
    17. How to get IP header of a UDP message
    18. Writing UDP/SOCK_DGRAM applications
    19. How many bytes in an IPX network address?
    20. What is the difference between MUTEX and Semaphore?
    21. What is priority inversion?
    22. Different Solutions to dining philosophers problem.
    23. What is a message queue?
    24. Questions on Shared Memory.
    25. What is DHCP?
    26. Working of ping, telnet, gopher.
    27. Can I connect two computers to internet using same line ?
    28. Working of TCP and SSL Handshake
    29. How P2P softwares work?
    30. Setting up TOMCAT web service
    31. Port numbers for FTP, HTTP, telnet, POP, finger
    32. Difference - Passive FTP, Active FTP
    33. Maximum Transmission Unit (MTU) what is it?
    34. Security threats due to use of CGI
    35. What is "spoofing"
    36. Where could you find Apache server web log
    37. Find web visitors by country
    38. What is Virtual Private Network (VPN) and how does it work?
    39. How does routing work? 
================================================================================
► How do I open a socket?
Sol:
    Using socket api
        socket(int domain, int type, int protocol);
    eg: socket(AF_INET, SOCK_STREAM, 0);
================================================================================
► How do I create an input stream?
Sol:
    Using read, recvfrom, recvmsg, recv Api
    ssize_t read(int fd, void *buf, size_t count)
    ssize_t recv(int sockfd, void *buf, size_t len, int flags)
    ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags)
    ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags)
================================================================================
► How do I create an output stream?
Sol:
    Using write, send, sendto, sendmsg API
    ssize_t write(int fd, const void *buf, size_t count)
    ssize_t send(int sockfd, const void *buf, size_t len, int flags,
                 const struct sockaddr *dest_addr, socklen_t addrlen)
    ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);
================================================================================
    
► How do I close sockets?
Sol:
    Using close, shutdown API
    int close(int fd)
    int shutdown(int sockfd, int how)
================================================================================
► Explain simple mail transfer protocol?
► Explain simple Echo server?
► What this function socketpair() does?
► What this function socket() does?
► What this function bind() does?
► What this function connect() does?
► What this function sendto() does?
► What this function recvfrom() does?
► How to disposing of a Socket?
► How Sockets can be used to write client-server applications using a connection-oriented client-server technique?
► How to make a Socket a Listen-only Connection Endpoint - listen()?
► Explain Connection Establishment by Server - accept()?
► Explain Data Transfer over Connected Sockets - send() and recv()?
► Explain with a Connection-Oriented Example - listen(), accept()?
► What is the IP Address?
► What is Network Host Names?
► What is the /etc/hosts File?
► How to Selecte a Service Port?
► How to Put a Host Program Address Together?
► How to finding a Machine Address?
► Explain Routines for converting data between a hosts internal representation and Network Byte Order?
► Explain Network Address Conversion Routines?
► RMI vs. Sockets and Object Serialization
► Explain How does the client receives the object and prints the date?
► Explain A multi-threaded DateServe that listens on port 3000 and 
  waits for requests from clients?
► Shows how to read a serialized object and print its information?
► Shows how to save a Date object to a file?
► Explain How do sockets work?
► What are basic functions of network programming interface?
► What is Whois Client?
► How to run the WHOIS Daemon?
► What is Whois Daemon?
► What is Inetd Services?
► How do we get a process bound behind a port?
► What is Socket Addressing?
► What is File Descriptors and Sockets?
► What is Client Connect?
► What is Server Applications?



Poject Description:
===================
Develop TCP/IP client/server programs to simulate the full-duplex stop-and-wait
data link protocol:

1. Write a connection-oriented File Server (FS) program to do the following:

        a. Print the FS address (hostname, port_number, server name) on the screen.
        b. Accept a connection request from the client.
        c. Fork/Create a child process/thread to process the client request:
           Receive the file uploaded from the client in a number of data frames using the 
           stop-and-wait protocol with Positive and Negative acknowledgment.
           FRAME data structure used should be the same as your previous assignment.


2. Write a client program to do the following:

        a. Connect to the FS server using the FS address printed on the server screen.
        b. Upload an image file to the FS server simulating the stop-and-wait protocol
           with Positive and Negative acknowledgment. Simulate the transmission errors 
           by using random number generating function.
           (Optional: To decelop a full-duplex TCP connection on the client side so that 
           it can send data packets and read acknowledgement at the same time by two 
           different processes/threads.)

Protocol specifications:

        a. Client and FS server communication should use the TCP/IP connection-oriented service.
           The FRAME data size is limited to 1024-byte and 1-bit sending window size should be used.
           You should use the sleep() function to simulate the transmission delay and message rate.
        b. FS server must be a multi-process/multi-thread program to be able to serve multiple clients.
        c. Assume the Data frames have 20% transmission errors, but they will not be lost.
           Short ACK/NACK frames will not have transmission errors.
           (Therefore no timer is needed to simulate this protocol.)
        d. Using a random number generator (rand(...)) to simulate the transmission errors.

